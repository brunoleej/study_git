import tensorflow as tf
import matplotlib.pyplot as plt

x = [1., 2., 3.]
y = [2., 4., 6.]

w = tf.compat.v1.placeholder(tf.float32)

hypothesis = x * w

cost = tf.reduce_mean(tf.square(hypothesis - y))    # loss = 'mse'
# cost = tf.reduce_mean(tf.abs(hypothesis - y))    # loss = 'mae'

w_history = []
cost_history = []

with tf.compat.v1.Session() as sess :
    # Variable이라고 따로 선언해준 것이 없기 떄문에 초기화를 하지 않아도 작동이 된다.

    for i in range (-30, 50) :
        curr_w = i * 0.1    # -3 부터 5까지 0.1 간격으로
        curr_cost = sess.run(cost, feed_dict={w:curr_w})    # curr_w값을 넣은 hypothesis로 cost를 구한다.

        w_history.append(curr_w)    # weight 축적 -> x축
        cost_history.append(curr_cost)  # cost 축적 -> y축

print("==================================")
print(w_history)
print("==================================")
print(cost_history)
print("==================================")


plt.plot(w_history, cost_history)
plt.show()

'''==================================
[-3.0, -2.9000000000000004, -2.8000000000000003, -2.7, -2.6, -2.5, -2.4000000000000004, -2.3000000000000003, -2.2, -2.1, -2.0, -1.9000000000000001, -1.8, -1.7000000000000002, -1.6, -1.5, -1.4000000000000001, -1.3, 
-1.2000000000000002, -1.1, -1.0, -0.9, -0.8, -0.7000000000000001, -0.6000000000000001, -0.5, -0.4, -0.30000000000000004, -0.2, -0.1, 0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0, 1.1, 1.2000000000000002, 1.3, 1.4000000000000001, 1.5, 1.6, 1.7000000000000002, 1.8, 1.9000000000000001, 2.0, 2.1, 2.2, 2.3000000000000003, 2.4000000000000004, 2.5, 2.6, 2.7, 2.8000000000000003, 2.9000000000000004, 3.0, 3.1, 3.2, 3.3000000000000003, 3.4000000000000004, 3.5, 3.6, 3.7, 3.8000000000000003, 3.9000000000000004, 4.0, 4.1000000000000005, 4.2, 4.3, 4.4, 4.5, 4.6000000000000005, 4.7, 4.800000000000001, 4.9]
==================================
[116.666664, 112.04667, 107.52, 103.08667, 98.746666, 94.5, 90.34668, 86.28666, 82.32, 78.446655, 74.666664, 70.98, 67.386665, 63.88667, 60.48, 57.166668, 53.946667, 50.819996, 47.78667, 44.84667, 42.0, 39.246666, 
36.586662, 34.020004, 31.546667, 29.166666, 26.88, 24.686666, 22.586664, 20.58, 18.666666, 16.846666, 15.12, 13.486667, 11.946668, 10.5, 9.146666, 7.886667, 6.72, 5.6466675, 4.6666665, 3.7799995, 2.9866664, 2.286667, 1.6800003, 1.1666666, 0.7466665, 0.41999972, 0.18666685, 0.04666671, 0.0, 0.046666577, 0.18666685, 0.41999972, 0.74666697, 1.1666666, 1.6799995, 2.2866673, 2.986666, 3.7800019, 4.6666665, 5.646665, 6.720001, 7.8866653, 9.146669, 10.5, 11.946664, 13.486669, 15.119998, 16.84667, 18.666666, 20.579996, 22.586664, 24.68667, 26.880005, 29.166666, 31.546661, 34.019997, 36.586674, 39.24667]
==================================
'''
